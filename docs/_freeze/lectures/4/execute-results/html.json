{
  "hash": "36ff0c29bba8528cd9696cf25f300a29",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Monte Carlo Methods\"\nsubtitle: \"Integration and Optimization\"\nformat:\n  revealjs:\n    scrollable: true\n    navigation-mode: vertical\n    controls-layout: bottom-right\n    controls-tutorial: true\n    incremental: false \n    chalkboard:\n      src: chalkboard.json\n      storage: chalkboard_pres\n      theme: whiteboard\n      chalk-width: 4\nengine: knitr\nknitr:\n  opts_chunk: \n    code-fold: true\n    echo: true\n    eval: true\n    comment: \"#>\" \nfilters: \n  - reveal-header\n  - reveal-auto-agenda\n  - code-fullscreen\n  - webr\nwebr: \n  show-startup-message: true\n  packages: ['ggplot2', 'dplyr', 'stringr']\neditor_options: \n  chunk_output_type: console\n---\n\n\n## R Packages\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nlibrary(tidyverse)\n```\n:::\n\n \n\n# Monte Carlo Integration\n\n## Monte Carlo Integration\n\nMonte Carlo Integration is a numerical technique to compute a numerical of an integral.\n\nIt relies on simulating from a know distribution to obtain the expected value of a desired function.\n\n## Integration\n\nIntegration is commonly used to find the area under a curve.\n\n## Expectation\n\nLet $X$ be a continuous random variable:\n\n$$\nE(X) = \\int_{X}xf(x)dx \n$$\n\n$$\nE\\{g(X)\\} = \\int_Xg(x)f(x)dx\n$$\n\n\n## Strong Law of Large Numbers\n\nAs $n\\rightarrow \\infty$ (ie simulate a large number of random variables):\n\n$$\n\\bar X_n \\rightarrow E_f(X)\n$$\n\nwhere\n\n$$\n\\bar X_n \\rightarrow = \\frac{1}{n}\\sum^n_{i=1}X_i\n$$\n## Strong Law of Large Numbers\n\n$$\n\\bar X_n^{(g)} \\rightarrow E_f\\{g(X)\\}\n$$\n\nwhere\n\n$$\n\\bar X_n^{(g)} \\rightarrow = \\frac{1}{n}\\sum^n_{i=1}g(X_i)\n$$\n\n## The Expected Value of a Normal Distribution\n\n$$\nE(X) = \\int^{\\infty}_{-\\infty}\\frac{x}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left\\{-\\frac{(x-\\mu)^2}{\\sigma^2}\\right\\} dx = \\mu\n$$\n\n## Variance of a Normal Distribution\n\n$$\nVar(X) = E[\\{X-E(X)\\}^2] \\\\= \\int^{\\infty}_{-\\infty}\\frac{\\{x-E(X)\\}^2}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left\\{-\\frac{(x-\\mu)^2}{\\sigma^2}\\right\\} dx = \\sigma^2\n$$\n\n## Using Monte Carlo Integration to obtain expectations\n\n1. Simulate from a target distribution $f$\n2. Calculate the mean for the expected value\n\n\n## Using Monte Carlo Integration\n\n$$\nX \\sim N(\\mu, \\sigma^2)\n$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- rnorm(100000, mean = -2, sd = 3)\nmean(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] -1.982628\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"true\"}\nvar(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 8.960177\n```\n\n\n:::\n:::\n\n\n\n## Gamma Distrbution\n\n$$\nX \\sim Gamma(3,4)\n$$\n\n## Beta Distribution\n\n$$\nX \\sim Beta(2,3)\n$$\n\n## $\\chi^2(p)$\n\n$$\nX \\sim \\chi^2(39)\n$$ \n\n## Finding the Probability\n\nIntegration is commonly used to determine the probability of observing a certain range of values for a continuous random variable.\n\n$$\nP(a < X < b)\n$$\n\n## Graphical Setting\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- seq(-4, 4, length.out = 1000)\ndt_two<-function(x){\n            y <- dnorm(x)\n            y[x< -1 | x>2] <-NA\n            return(y)\n        }\nx |> (\\(.) tibble(x = ., y = dnorm(.)))() |> \n  ggplot(aes(x, y)) +\n    geom_line() +\n    stat_function(fun = dt_two, geom = \"area\", fill = \"green\") + \n    theme_bw()\n```\n\n::: {.cell-output-display}\n![](4_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n## Finding the Propbabilities of a Random Variable\n\nFor a given random variable $X$, finding the probability is the same as\n\n$$\nE\\{I(a<X<b)\\} = \\int_X I(a<X<b) f(x) dx\n$$\n\nwhere $I(a<X<b)$ is the indicator function.\n\n## Indicator Function\n\n$$\nI(a<X<b) = \\left\\{\\begin{array}{cc}\n1 & a<X<b\\\\\n0 & \\mathrm{otherwise}\n\\end{array}\n\\right.\n$$\n\n## Finding the Probability\n\n$$\n\\begin{align}\nE\\{I(a<X<b)\\} &  = \\int_X I(a<X<b) f(x) dx\\\\ \n & = \\int_a^b f(x) dx\\\\\n & = P(a < X < b)\n\\end{align}\n$$\n\n## Monte Carlo Probability\n\n1. Simulate from a target distribution $f$\n2. Calculate the mean for $I(a<X<b)$\n\n## Normal RV Example\n\nLet $X\\sim N(4, 2)$, find $P(3 < X < 6)$\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\npnorm(6, 4, sqrt(2)) -  pnorm(3, 4, sqrt(2))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.6816003\n```\n\n\n:::\n:::\n\n\n## Using Monte Carlo Methods\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nx <- rnorm(1000000, 4, sqrt(2))\nmean((x > 3 & x < 6))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.681814\n```\n\n\n:::\n:::\n\n\n\n## Logistic RV Example\n\nLet $X\\sim Logistic(3, 5)$, find $P(-1 < X < 5)$\n\n\n## Weibull RV Example\n\nLet $X\\sim Weibull(1, 1)$, find $P(2 < X < 5.5)$\n\n\n## F RV Example\n\nLet $X\\sim F(2, 45)$, find $P(1 < X < 3)$\n\n\n## Monte Carlo Integration\n\nMonte Carlo Integration can be used to evaluate finite-bounded integrals of the following form:\n\n$$\n\\int^b_a g(x) dx\n$$\nsuch that $-\\infty <a,b<\\infty$.\n\n## Monte Carlo Example Integration\n\n$$\n\\int^1_{0} \\{\\cos(50x) - sin(20x)\\}^2dx\n$$\n\n## Monte Carlo Example Integration\n\nLet $X \\sim U(0,1)$ with $f(x) = 1$, then\n\n$$\nE[\\{\\cos(50x) - sin(20x)\\}^2] =\\int^1_{0} \\{\\cos(50x) - sin(20x)\\}^2dx\n$$\n\n## Using Numerical Integration\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nff <- function(x){\n  (cos(50*x)-sin(50*x))^2\n}\nintegrate(ff,0,1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> 0.9986232 with absolute error < 9.5e-11\n```\n\n\n:::\n:::\n\n\n\n## Monte Carlo Example Integration\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- runif(10000000, 0, 1)\nmean((cos(50*x)-sin(50*x))^2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.9984644\n```\n\n\n:::\n:::\n\n\n\n## Monte Carlo Example Integration\n\n$$\n\\int^{15}_{10} \\{\\cos(50x) - sin(20x)\\}^2dx\n$$\n\n## Monte Carlo Integration\n\nLet $X \\sim U(10,15)$ with $f(x) = 1$, then\n\n$$\nE[\\{\\cos(50x) - sin(20x)\\}^2] = \\\\\n\\int^{15}_{10} \\frac{1}{5} \\{\\cos(50x) - sin(20x)\\}^2dx\n$$\n\n## Monte Carlo Example Integration\n\n$$\n\\int^{15}_{10} \\{\\cos(50x) - sin(20x)\\}^2dx = \\\\\n5 * E[\\{\\cos(50x) - sin(20x)\\}^2]\n$$\n\n## Monte Carlo Example Integration\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nff <- function(x){\n  (cos(50*x)-sin(50*x))^2\n}\nintegrate(ff,10,15)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> 4.993274 with absolute error < 1.1e-06\n```\n\n\n:::\n:::\n\n\n## Monte Carlo Example Integration\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nx <- runif(10000000, 10, 15)\nmean(ff(x)) * 5\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 4.994546\n```\n\n\n:::\n:::\n\n\n## Monte Carlo Integration Algorithm\n\nGiven: \n$$\n\\int_a^b g(x) dx\n$$\n\n1.    Simulate $n$ value from $X \\sim U(a,b)$\n2.    Take the average, $\\frac{1}{n}\\sum^{n}_{i=1}g(x_i)$\n3.    Multiply the average by $b-a$: $\\frac{b-a}{n}\\sum^{n}_{i=1}g(x_i)$\n\n## MC Examples\n\n$$\n\\int_0^{2}  e^{-x^2/2} dx\n$$\n\n# Importance Sampling\n\n## Importance Sampling\n\nImportance sampling is an extension of Monte Carlo integration where it addresses the limitations of large variance of the expected value and the bounds required in integrals.\n\nThis is done by simulating from a random variable that has an infinite support system.\n\n## Importance Sampling\n\nLet's say we are interested in finding the numerical value of the following integral:\n\n$$\n\\int_{-\\infty}^\\infty g(x) dx\n$$\n\n## Importance Sampling\n\nIf we view the integral as an expectation of an easily simulated random variable, we can compute the numerical value.\n\nLet $X$ be a random variable $f$, then\n\n$$\n\\int_{-\\infty}^\\infty g(x) dx = \\int_{-\\infty}^\\infty \\frac{g(x)}{f(x)} f(x) dx = E\\left\\{\\frac{g(x)}{f(x)}\\right\\}\n$$\n\n## Importance Sampling\n\nSince the integral is the expectation of $X$, it can be obtained by taking the mean of the simulated values applied to $g(x)/f(x)$.\n\n## Example\n\n$$\n\\int_{-\\infty}^{\\infty}  e^{-x^2/2} dx\n$$\n\n## Example\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- rt(1000000, df = 1)\nf2 <- function(x){\n  exp(-x^2/2) / dt(x, 1)\n}\nmean(f2(x))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 2.506316\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"true\"}\nsqrt(2*pi)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 2.506628\n```\n\n\n:::\n:::\n\n\n\n## Choosing $f(x)$\n\nChoose a value $f(x)$ that follows a shape close enough to $g(x)$ that has the same bounds as the integral.\n\n\n## Example\n\n$$\n\\int_{-\\infty}^{\\infty}  e^{-(x-4)^2/10} dx\n$$\n## Example\n\n$$\n\\int_{0}^{\\infty} x^3 e^{x/2} dx\n$$\n\n# Monte Carlo Optimization\n\n## Optimization\n\n$$\nh(x) = -3x^4+4x^3\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nff <- function(x){\n  -3*x^4+4*x^3\n}\nx <- seq(-1, 2, length.out = 1000) \ny <- ff(x)\ntibble(x, y) |> \n  ggplot(aes(x, y)) +\n  geom_line() + theme_bw()\n```\n\n::: {.cell-output-display}\n![](4_files/figure-revealjs/unnamed-chunk-11-1.png){width=960}\n:::\n:::\n\n\n## Optimization\n\nOptimization is the method to find the values of a variable that will maximize a function of interest ($h$).\n\n## Numerical Optimization Techniques\n\n::: incremental\n- Newton-Raphson Method\n- Gradient Descent\n- Quasi Newton-Raphson Method\n:::\n\n## Monte Carlo Optimization\n\nMonte Carlo Optimization technique a brute force method that will simulate a high number of random values, evaluate them with $h(x)$, and identify which value provides a the maximum value.\n\n## Optimization\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nff <- function(x){\n  y <- -3*x^4+4*x^3\n  return(y)\n}\nx <- seq(-1, 2, length.out = 1000) \ny <- ff(x)\ntibble(x, y) |> \n  ggplot(aes(x, y)) +\n  geom_line() + theme_bw()\n```\n\n::: {.cell-output-display}\n![](4_files/figure-revealjs/unnamed-chunk-12-1.png){width=960}\n:::\n:::\n\n\n## Numerical Optimization\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nff <- function(x){\n  y <- -3*x^4+4*x^3\n  return(-y)\n}\n\noptimize(ff, c(-5,5))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> $minimum\n#> [1] 1\n#> \n#> $objective\n#> [1] -1\n```\n\n\n:::\n:::\n\n \n## Monte Carlo Methods\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- runif(1000000, -5,5)\ny <- ff(x)\nwhich.min(y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 249139\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"true\"}\nx[which.min(y)]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 1.000004\n```\n\n\n:::\n:::\n\n\n## Monte Carlo Optimization\n\n$$\nf(x) =  e^{-(x-4)^2/10} \n$$\n\n## Monte Carlo Optimization\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- rnorm(1000)\ny <- 8 -4 * x + rnorm(1000, sd = 0.5)\nsse <- function(beta, x, y){\n  sum((y - (beta[1] + beta[2] * x))^2)\n}\nbeta0 <- seq(-20, 20, length.out = 50)\nbeta1 <- seq(-20, 20, length.out = 50)\nzz <- matrix(nrow = 50, ncol = 50)\nfor (i in seq_along(beta0)){\n  for(ii in seq_along(beta1)){\n    zz[i, ii] <- sse(c(beta0[i], beta1[ii]), x, y) \n  }\n}\npersp(beta0, beta1, zz)\n```\n\n::: {.cell-output-display}\n![](4_files/figure-revealjs/unnamed-chunk-15-1.png){width=960}\n:::\n:::\n",
    "supporting": [
      "4_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}