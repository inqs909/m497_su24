---
title: "Random Variable Generation"
format:
  revealjs:
    scrollable: true
    navigation-mode: vertical
    controls-layout: bottom-right
    controls-tutorial: true
    incremental: false 
    chalkboard:
      src: chalkboard.json
      storage: chalkboard_pres
      theme: whiteboard
      chalk-width: 4
engine: knitr
knitr:
  opts_chunk: 
    code-fold: true
    echo: true
    eval: true
    comment: "#>" 


filters: 
  - reveal-header
  - reveal-auto-agenda
  - code-fullscreen
  - webr

webr: 
  show-startup-message: true
  packages: ['ggplot2', 'dplyr', 'stringr']
---

# Random Variables

## Random Process

A random process is act of observing an outcome of an event that is unpredictable.

::: fragment
Examples:
-   Flipping a coin
-   Rolling a die
:::


## Random Variable

A random variable connects the outcomes observed from a random process to a probability space.

## Flipping a Coin
| | | |
|:-|:-|:-|
|Outcome | Head | Tails |
|Probability | 0.5 | 0.5 |

```{r}
#| fig-align: center
library(tidyverse)
library(patchwork)
x <- sample(c("H", "T"), 5000, replace = T)
x |> tibble() |> 
ggplot(aes(x)) +
geom_bar(aes(y = (..count..)/sum(..count..))) + 
ylab("Probability") +
theme_bw()
```



## Rolling a Die

| | | | | | | |
|:-|:-|:-|:-|:-|:-|:-|
|Outcome | 1 | 2 | 3 | 4 | 5 | 6 |
|Probability | 1/6 | 1/6 | 1/6 | 1/6 | 1/6 | 1/6 |

```{r}
#| fig-align: center
# library(tidyverse)
x <- sample(1:6, 50000, replace = T)
x |> tibble() |> 
ggplot(aes(x)) +
geom_bar(aes(y = (..count..)/sum(..count..))) + 
ylab("Probability") +
theme_bw()

```

## Discrete Random Variables

A random variable is considered to be discrete if the outcome are only whole numbers (integers).

## PMF

The probability mass function of discrete variable can be represented by a formula, table, or a graph. The Probability of a random variable Y can be expressed as $P(Y=y)$ for all values of $y$.

## Rolling a Die

```{r}
#| fig-align: center
x <- sample(1:6, 50000, replace = T)
x |> tibble() |> 
ggplot(aes(x)) +
geom_bar(aes(y = (..count..)/sum(..count..))) + 
ylab("Probability") +
theme_bw()

```


## CDF

The cumulative distribution function provides the $P(Y\leq y)$ for a random variable $Y$.

## Expected Value

The *expected value* is the value we expect when we randomly sample from population that follows a specific distribution. The expected value of Y is

$$
E(Y)=\sum_y yP(y)
$$

## Variance

The *variance* is the expected squared difference between the random variable and expected value.

$$
Var(Y)=\sum_y\{y-E(Y)\}^2P(y)
$$

$$
Var(Y) = E(X^2) - E(X)^2
$$

## Known Distributions

| Distribution      | Parameter(s)      | PMF $P(Y=y)$                          |
|------------------|------------------|------------------------------------|
| Bernoulli         | $p$               | $p$                                   |
| Binomial          | $n$ and $p$       | $(^n_y)p^y(1-p)^{n-p}$                |
| Geometric         | $p$               | $(1-p)^{y-1}p$                        |
| Negative Binomial | $r$ and $p$       | $(^{y-1}_{r-1})p^{r-1}(1-p)^{y-r}$    |
| Hypergeometric    | $N$, $n$, and $r$ | $\frac{(^r_y)(^{N-r}_{n-y})}{(^N_n)}$ |
| Poisson           | $\lambda$         | $\frac{\lambda^y}{y!} e^{-\lambda}$   |


## Binomial Distribution

An experiment is said to follow a binomial distribution if

1.  Fixed $n$
2.  Each trial has 2 outcomes
3.  The probability of success is a constant $p$
4.  The trials are independent of each

::: fragment
$P(X=x)=(^n_x)p^x(1-p)^{n-x}$
:::

::: fragment
$X$ can be any value between 0 to n
:::

::: fragment
$X \sim Bin(n,p)$
:::

## Bernoulli Distribution (n = 1, p = 0.1; Biased Coin Flip)

```{r}
p <- 0.1
x <- rbinom(50000, 1, p)
p1 <- x |> tibble() |> 
ggplot(aes(x)) +
geom_bar(aes(y = (..count..)/sum(..count..))) + 
ylab("Probability") +
ggtitle("PMF") +
theme_bw()
p2 <- 0:1 |> pbinom(1, p) |> tibble(x = 0:1, y = _) |> 
ggplot(aes(x,y)) +
geom_line() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```


## Distribution (n = 30, p = 0.1)

```{r}
p <- 0.1
x <- rbinom(50000, 30, p)
p1 <- x |> tibble() |> 
ggplot(aes(x)) +
geom_bar(aes(y = (..count..)/sum(..count..))) + 
xlim(c(0,30)) +
ylab("Probability") +
ggtitle("PMF") +
theme_bw()
p2 <- 0:30 |> pbinom(30, p) |> tibble(x = 0:30, y = _) |> 
ggplot(aes(x,y)) +
geom_line() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```

## Distribution (n = 30, p = 0.5)

```{r}
p <- 0.5
x <- rbinom(50000, 30, p)
p1 <- x |> tibble() |> 
ggplot(aes(x)) +
geom_bar(aes(y = (..count..)/sum(..count..))) + 
xlim(c(0,30)) +
ylab("Probability") +
ggtitle("PMF") +
theme_bw()
p2 <- 0:30 |> pbinom(30, p) |> tibble(x = 0:30, y = _) |> 
ggplot(aes(x,y)) +
geom_line() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```

## Distribution (n = 30, p = 0.85)

```{r}
p <- 0.85
x <- rbinom(50000, 30, p)
p1 <- x |> tibble() |> 
ggplot(aes(x)) +
geom_bar(aes(y = (..count..)/sum(..count..))) + 
xlim(c(0,30)) +
ylab("Probability") +
ggtitle("PMF") +
theme_bw()
p2 <- 0:30 |> pbinom(30, p) |> tibble(x = 0:30, y = _) |> 
ggplot(aes(x,y)) +
geom_line() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```

## Expectations

$$
E(X) =  np
$$

$$
Var(X) = np(1-p)
$$

## Poisson Distribution

The poisson distribution describes an experiment that measures that occurrence of an event at specific point and/or time period.

::: fragment
$P(X=x)=\frac{\lambda^x}{x!}e^{-\lambda}$
:::

::: fragment
$X$ can take any value from 0 to $\infty$
:::

::: fragment
$X \sim Pois(\lambda)$
:::


## Distribution ($\lambda$ = 3.5)

```{r}
p <- 3.5
x <- rpois(50000, p)
p1 <- x |> tibble() |> 
ggplot(aes(x)) +
geom_bar(aes(y = (..count..)/sum(..count..))) + 
ylab("Probability") +
ggtitle("PMF") +
theme_bw()
p2 <- 0:max(x) |> ppois(p) |> tibble(x = 0:max(x), y = _) |> 
ggplot(aes(x,y)) +
geom_line() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```

## Distribution ($\lambda$ = 34.5)

```{r}
p <- 34.5
x <- rpois(50000, p)
p1 <- x |> tibble() |> 
ggplot(aes(x)) +
geom_bar(aes(y = (..count..)/sum(..count..))) + 
ylab("Probability") +
ggtitle("PMF") +
theme_bw()
p2 <- 0:max(x) |> ppois(p) |> tibble(x = 0:max(x), y = _) |> 
ggplot(aes(x,y)) +
geom_line() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```

## Expectations

$$
E(X) = \lambda
$$

$$
Var(X) = \lambda
$$


## Negative Binomial

The negative binomial distribution is a discrete probability distribution that models the number of trials required to achieve a specified number of successes in a sequence of independent and identically distributed Bernoulli trials. 

$$
P(X = k) = \binom{k + r - 1}{r - 1} p^r (1 - p)^k
$$

::: fragment
$X$ can take the values from 0 to $\infty$
:::

::: fragment
$X\sim NB(p, r)$
:::

## Expectations

$$
E(X) = \frac{r (1 - p)}{p}
$$

$$
\text{Var}(X) = \frac{r (1 - p)}{p^2}
$$

## Distribution (r = 11, p = 0.1)

```{r}
p <- 0.1
x <- rnbinom(50000, 11, p)
p1 <- x |> tibble() |> 
ggplot(aes(x)) +
geom_bar(aes(y = (..count..)/sum(..count..))) +
ylab("Probability") +
ggtitle("PMF") +
theme_bw()
p2 <- 0:max(x) |> pnbinom(11, p) |> tibble(x = 0:max(x), y = _) |> 
ggplot(aes(x,y)) +
geom_line() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```

## Distribution (r = 11, p = 0.45)

```{r}
p <- 0.45
x <- rnbinom(50000, 11, p)
p1 <- x |> tibble() |> 
ggplot(aes(x)) +
geom_bar(aes(y = (..count..)/sum(..count..))) +
ylab("Probability") +
ggtitle("PMF") +
theme_bw()
p2 <- 0:max(x) |> pnbinom(11, p) |> tibble(x = 0:max(x), y = _) |> 
ggplot(aes(x,y)) +
geom_line() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```

## Distribution (r = 11, p = 0.63)

```{r}
p <- 0.63
x <- rnbinom(50000, 11, p)
p1 <- x |> tibble() |> 
ggplot(aes(x)) +
geom_bar(aes(y = (..count..)/sum(..count..))) +
ylab("Probability") +
ggtitle("PMF") +
theme_bw()
p2 <- 0:max(x) |> pnbinom(11, p) |> tibble(x = 0:max(x), y = _) |> 
ggplot(aes(x,y)) +
geom_line() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```

## Continuous Random Variables

A random variable $X$ is considered continuous if the $P(X=x)$ does not exist.

## CDF

The cumulative distribution function of $X$ provides the $P(X\leq x)$, denoted by $F(x)$, for the domain of $X$.

Properties of the CDF of $X$:

1.  $F(-\infty)\equiv \lim_{y\rightarrow -\infty}F(y)=0$
2.  $F(\infty)\equiv \lim_{y\rightarrow \infty}F(y)=1$
3.  $F(x)$ is a nondecreaseing function

## PDF

The probability density function of the random variable $X$ is given by

$$
f(x)=\frac{dF(x)}{d(x)}=F^\prime(x)
$$

wherever the derivative exists.

Properties of pdfs:

1.  $f(x)\geq 0$
2.  $\int^\infty_{-\infty}f(x)dx=1$
3.  $P(a\leq X\leq b) = P(a<X<b)=\int^b_af(x)dx$

## Expected Value

The expected value for a continuous distribution is defined as

$$
E(X)=\int x f(x)dx
$$

The expectation of a function $g(X)$ is defined as

$$
E\{g(X)\}=\int g(x)f(x)dx
$$

## Variance

The variance of continuous variable is defined as

$$
Var(X) =  E[\{X-E(X)\}^2] = \int \{X-E(X)\}^2 f(x)dx 
$$



## Uniform Distribution

A random variable is said to follow uniform distribution if the density function is constant between two parameters.

::: fragment
$$
f(x) = \left\{\begin{array}{cc}
 \frac{1}{b-a} & a \leq x \leq b\\
0 & \mathrm{elsewhere}
\end{array}\right.
$$
:::

::: fragment
$X$ can take any value between $a$ and $b$
:::

::: fragment
$X \sim U(a,b)$
:::



## Distribution (a = 4, b = 25)

```{r}
a <- 4
b <- 25
x <- seq(a, b, length.out = 1000)
p1 <- dunif(x, a, b) |> tibble(x = x, y = _) |> 
ggplot(aes(x, y)) +
geom_line() +
ylab("Density") +
ggtitle("PDF") +
theme_bw()
p2 <- punif(x, a, b) |> tibble(x = x, y = _) |> 
ggplot(aes(x,y)) +
geom_line() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```


## Distribution (a = 0, b = 1)

```{r}
a <- 0
b <- 1
x <- seq(a, b, length.out = 1000)
p1 <- dunif(x, a, b) |> tibble(x = x, y = _) |> 
ggplot(aes(x, y)) +
geom_line() +
ylab("Density") +
ggtitle("PDF") +
theme_bw()
p2 <- punif(x, a, b) |> tibble(x = x, y = _) |> 
ggplot(aes(x,y)) +
geom_line() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```

## Expectations

$$
E(X) = \frac{a+b}{2}
$$

$$
Var(X) = \frac{1}{12}(b-a)^2
$$



## Normal Distribution

A random variable is said to follow a normal distribution if the the frequency of occurrence follow a Gaussian function.

$$
f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left\{-\frac{(x-\mu)^2}{2\sigma^2}\right\}
$$

::: fragment
$X$ can take any value between $-\infty$ and $\infty$
:::

::: fragment
$X\sim N(\mu, \sigma^2)$
:::

## Distribution ($\mu$ = 34, $\sigma^2$ = 5)

```{r}
a <- 25
b <- 45
x <- seq(a, b, length.out = 1000)
p1 <- dnorm(x, 34, sqrt(5)) |> tibble(x = x, y = _) |> 
ggplot(aes(x, y)) +
geom_line() +
ylab("Density") +
ggtitle("PDF") +
theme_bw()
p2 <- pnorm(x, 34, sqrt(5)) |> tibble(x = x, y = _) |> 
ggplot(aes(x,y)) +
geom_line() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```

## Distribution ($\mu$ = -8, $\sigma^2$ = 10)

```{r}
a <- -20
b <- 4
x <- seq(a, b, length.out = 1000)
p1 <- dnorm(x, -8, sqrt(10)) |> tibble(x = x, y = _) |> 
ggplot(aes(x, y)) +
geom_line() +
ylab("Density") +
ggtitle("PDF") +
theme_bw()
p2 <- pnorm(x, -8, sqrt(10)) |> tibble(x = x, y = _) |> 
ggplot(aes(x,y)) +
geom_line() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```

## Expectations 

$$
E(X) = \mu
$$

$$
Var(X) = \sigma^2
$$

## Gamma Distribution

A gamma random variable is characterized by the gamma distribution, used to model waiting times or the time until an event occurs a certain number of times.

$$
f(x; \alpha, \beta) = \frac{x^{\alpha - 1} e^{-x/\beta}}{\beta^\alpha \Gamma(\alpha)}
$$

$$
\Gamma(\alpha) = \int_0^\infty t^{\alpha - 1} e^{-t} \, dt
$$

::: fragment
$X$ can take any value between 0 and $\infty$
:::

::: fragment
$X\sim Gamma(\alpha,\beta)$
:::

## Expectations

$$
E(X) = \alpha \beta
$$

$$
\text{Var}(X) = \alpha \beta^2
$$

## Beta Distribution

The beta distribution is often used to model random variables that represent proportions or probabilities.

$$
f(x; \alpha, \beta) = \frac{x^{\alpha - 1} (1 - x)^{\beta - 1}}{B(\alpha, \beta)}
$$

$$
B(\alpha, \beta) = \int_0^1 t^{\alpha - 1} (1 - t)^{\beta - 1} \, dt
$$

::: fragment
$X$ can take a value between 0 and 1
:::

::: fragment
$X\sim Beta(\alpha,\beta)$
:::

## Expectations

$$
E(X) = \frac{\alpha}{\alpha + \beta}
$$

$$
\text{Var}(X) = \frac{\alpha \beta}{(\alpha + \beta)^2 (\alpha + \beta + 1)}
$$

# Random Number Generator History

## Generating Random Numbers

![](https://content.presentermedia.com/files/clipart/00002000/2605/pair_of_white_dice_rolled_800_wht.jpg)

## Generating Random Numbers

![](https://www.pbs.org/newshour/app/uploads/2015/03/159615168-1024x768.jpg)

## Generating Random Numbers

![](https://cdn.mos.cms.futurecdn.net/gGpxdnJ7x3dBMrgSgKybQU-1200-80.jpg)

## Generating Random Numbers

![](https://mathbitsnotebook.com/Algebra2/Statistics/random%20table.png)

## Generating Random Numbers

![](https://cdn.britannica.com/35/18435-050-C6ECB9CB/Monte-Carlo-casino.jpg)

## Psuedo Random Numbers

## Modulo 2 Linear Generators

## Mersenne Twister

# Random Variable Generations