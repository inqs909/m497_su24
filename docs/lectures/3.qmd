---
title: "Monte Carlo Methods"
subtitle: "Random Variable Generation"
format:
  revealjs:
    scrollable: true
    navigation-mode: vertical
    controls-layout: bottom-right
    controls-tutorial: true
    incremental: false 
    chalkboard:
      src: chalkboard.json
      storage: chalkboard_pres
      theme: whiteboard
      chalk-width: 4
engine: knitr
knitr:
  opts_chunk: 
    code-fold: true
    echo: true
    eval: true
    comment: "#>" 
filters: 
  - reveal-header
  - reveal-auto-agenda
  - code-fullscreen
  - webr
webr: 
  show-startup-message: true
  packages: ['ggplot2', 'dplyr', 'stringr']
editor_options: 
  chunk_output_type: console
---

# Random Variables

## Random Process

A random process is act of observing an outcome of an event that is unpredictable.

::: fragment
Examples:

-   Flipping a coin

-   Rolling a die

:::


## Random Variable

A random variable connects the outcomes observed from a random process to a probability space.

## Flipping a Coin
| | | |
|:-|:-|:-|
|Outcome | Head | Tails |
|Probability | 0.5 | 0.5 |

```{r}
#| fig-align: center
library(tidyverse)
library(patchwork)
x <- sample(c("H", "T"), 5000, replace = T)
x |> tibble() |> 
ggplot(aes(x)) +
geom_bar(aes(y = (..count..)/sum(..count..))) + 
ylab("Probability") +
theme_bw()
```



## Rolling a Die

| | | | | | | |
|:-|:-|:-|:-|:-|:-|:-|
|Outcome | 1 | 2 | 3 | 4 | 5 | 6 |
|Probability | 1/6 | 1/6 | 1/6 | 1/6 | 1/6 | 1/6 |

```{r}
#| fig-align: center
# library(tidyverse)
x <- sample(1:6, 50000, replace = T)
x |> tibble() |> 
ggplot(aes(x)) +
geom_bar(aes(y = (..count..)/sum(..count..))) + 
ylab("Probability") +
theme_bw()

```

## Discrete Random Variables

A random variable is considered to be discrete if the outcome are only whole numbers (integers).

## PMF

The probability mass function of discrete variable can be represented by a formula, table, or a graph. The Probability of a random variable Y can be expressed as $P(Y=y)$ for all values of $y$.

## Rolling a Die

```{r}
#| fig-align: center
x <- sample(1:6, 50000, replace = T)
x |> tibble() |> 
ggplot(aes(x)) +
geom_bar(aes(y = (..count..)/sum(..count..))) + 
ylab("Probability") +
theme_bw()

```


## CDF

The cumulative distribution function provides the $P(Y\leq y)$ for a random variable $Y$.

## Expected Value

The *expected value* is the value we expect when we randomly sample from population that follows a specific distribution. The expected value of Y is

$$
E(Y)=\sum_y yP(y)
$$

## Variance

The *variance* is the expected squared difference between the random variable and expected value.

$$
Var(Y)=\sum_y\{y-E(Y)\}^2P(y)
$$

$$
Var(Y) = E(X^2) - E(X)^2
$$

## Known Distributions

| Distribution      | Parameter(s)      | PMF $P(Y=y)$                          |
|------------------|------------------|------------------------------------|
| Bernoulli         | $p$               | $p$                                   |
| Binomial          | $n$ and $p$       | $(^n_y)p^y(1-p)^{n-p}$                |
| Geometric         | $p$               | $(1-p)^{y-1}p$                        |
| Negative Binomial | $r$ and $p$       | $(^{y-1}_{r-1})p^{r-1}(1-p)^{y-r}$    |
| Hypergeometric    | $N$, $n$, and $r$ | $\frac{(^r_y)(^{N-r}_{n-y})}{(^N_n)}$ |
| Poisson           | $\lambda$         | $\frac{\lambda^y}{y!} e^{-\lambda}$   |


## Binomial Distribution

An experiment is said to follow a binomial distribution if

1.  Fixed $n$
2.  Each trial has 2 outcomes
3.  The probability of success is a constant $p$
4.  The trials are independent of each

::: fragment
$P(X=x)=(^n_x)p^x(1-p)^{n-x}$
:::

::: fragment
$X$ can be any value between 0 to n
:::

::: fragment
$X \sim Bin(n,p)$
:::

## Bernoulli Distribution (n = 1, p = 0.1; Biased Coin Flip)

```{r}
p <- 0.1
x <- rbinom(50000, 1, p)
p1 <- x |> tibble() |> 
ggplot(aes(x)) +
geom_bar(aes(y = (..count..)/sum(..count..))) + 
ylab("Probability") +
ggtitle("PMF") +
theme_bw()
p2 <- 0:1 |> pbinom(1, p) |> tibble(x = 0:1, y = _) |> 
ggplot(aes(x,y)) +
geom_step() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```


## Distribution (n = 30, p = 0.1)

```{r}
p <- 0.1
x <- rbinom(50000, 30, p)
p1 <- x |> tibble() |> 
ggplot(aes(x)) +
geom_bar(aes(y = (..count..)/sum(..count..))) + 
xlim(c(0,30)) +
ylab("Probability") +
ggtitle("PMF") +
theme_bw()
p2 <- 0:30 |> pbinom(30, p) |> tibble(x = 0:30, y = _) |> 
ggplot(aes(x,y)) +
geom_step() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```

## Distribution (n = 30, p = 0.5)

```{r}
p <- 0.5
x <- rbinom(50000, 30, p)
p1 <- x |> tibble() |> 
ggplot(aes(x)) +
geom_bar(aes(y = (..count..)/sum(..count..))) + 
xlim(c(0,30)) +
ylab("Probability") +
ggtitle("PMF") +
theme_bw()
p2 <- 0:30 |> pbinom(30, p) |> tibble(x = 0:30, y = _) |> 
ggplot(aes(x,y)) +
geom_step() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```

## Distribution (n = 30, p = 0.85)

```{r}
p <- 0.85
x <- rbinom(50000, 30, p)
p1 <- x |> tibble() |> 
ggplot(aes(x)) +
geom_bar(aes(y = (..count..)/sum(..count..))) + 
xlim(c(0,30)) +
ylab("Probability") +
ggtitle("PMF") +
theme_bw()
p2 <- 0:30 |> pbinom(30, p) |> tibble(x = 0:30, y = _) |> 
ggplot(aes(x,y)) +
geom_step() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```

## Expectations

$$
E(X) =  np
$$

$$
Var(X) = np(1-p)
$$

## Poisson Distribution

The poisson distribution describes an experiment that measures that occurrence of an event at specific point and/or time period.

::: fragment
$P(X=x)=\frac{\lambda^x}{x!}e^{-\lambda}$
:::

::: fragment
$X$ can take any value from 0 to $\infty$
:::

::: fragment
$X \sim Pois(\lambda)$
:::


## Distribution ($\lambda$ = 3.5)

```{r}
p <- 3.5
x <- rpois(50000, p)
p1 <- x |> tibble() |> 
ggplot(aes(x)) +
geom_bar(aes(y = (..count..)/sum(..count..))) + 
ylab("Probability") +
ggtitle("PMF") +
theme_bw()
p2 <- 0:max(x) |> ppois(p) |> tibble(x = 0:max(x), y = _) |> 
ggplot(aes(x,y)) +
geom_step() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```

## Distribution ($\lambda$ = 34.5)

```{r}
p <- 34.5
x <- rpois(50000, p)
p1 <- x |> tibble() |> 
ggplot(aes(x)) +
geom_bar(aes(y = (..count..)/sum(..count..))) + 
ylab("Probability") +
ggtitle("PMF") +
theme_bw()
p2 <- 0:max(x) |> ppois(p) |> tibble(x = 0:max(x), y = _) |> 
ggplot(aes(x,y)) +
geom_step() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```

## Expectations

$$
E(X) = \lambda
$$

$$
Var(X) = \lambda
$$

## Negative Binomial

The negative binomial distribution is a discrete probability distribution that models the number of failures required to achieve a specified number of successes in a sequence of independent and identically distributed Bernoulli trials. 

$$
P(X = k) = \binom{k + r - 1}{r - 1} p^r (1 - p)^k
$$

::: fragment
$X$ can take the values from 0 to $\infty$
:::

::: fragment
$X\sim NB(p, r)$
:::

## Expectations

$$
E(X) = \frac{r (1 - p)}{p}
$$

$$
\text{Var}(X) = \frac{r (1 - p)}{p^2}
$$

## Distribution (r = 11, p = 0.1)

```{r}
p <- 0.1
x <- rnbinom(50000,11, p)
p1 <- x |> tibble() |> 
ggplot(aes(x)) +
geom_bar(aes(y = (..count..)/sum(..count..))) +
ylab("Probability") +
ggtitle("PMF") +
theme_bw()
p2 <- 0:max(x) |> pnbinom(11, p) |> tibble(x = 0:max(x), y = _) |> 
ggplot(aes(x,y)) +
geom_step() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```

## Distribution (r = 11, p = 0.45)

```{r}
p <- 0.45
x <- rnbinom(50000, 11, p)
p1 <- x |> tibble() |> 
ggplot(aes(x)) +
geom_bar(aes(y = (..count..)/sum(..count..))) +
ylab("Probability") +
ggtitle("PMF") +
theme_bw()
p2 <- 0:max(x) |> pnbinom(11, p) |> tibble(x = 0:max(x), y = _) |> 
ggplot(aes(x,y)) +
geom_step() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```

## Distribution (r = 11, p = 0.63)

```{r}
p <- 0.63
x <- rnbinom(50000, 11, p)
p1 <- x |> tibble() |> 
ggplot(aes(x)) +
geom_bar(aes(y = (..count..)/sum(..count..))) +
ylab("Probability") +
ggtitle("PMF") +
theme_bw()
p2 <- 0:max(x) |> pnbinom(11, p) |> tibble(x = 0:max(x), y = _) |> 
ggplot(aes(x,y)) +
geom_step() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```

## Continuous Random Variables

A random variable $X$ is considered continuous if the $P(X=x)$ does not exist.

## CDF

The cumulative distribution function of $X$ provides the $P(X\leq x)$, denoted by $F(x)$, for the domain of $X$.

Properties of the CDF of $X$:

1.  $F(-\infty)\equiv \lim_{y\rightarrow -\infty}F(y)=0$
2.  $F(\infty)\equiv \lim_{y\rightarrow \infty}F(y)=1$
3.  $F(x)$ is a nondecreaseing function

## PDF

The probability density function of the random variable $X$ is given by

$$
f(x)=\frac{dF(x)}{d(x)}=F^\prime(x)
$$

wherever the derivative exists.

Properties of pdfs:

1.  $f(x)\geq 0$
2.  $\int^\infty_{-\infty}f(x)dx=1$
3.  $P(a\leq X\leq b) = P(a<X<b)=\int^b_af(x)dx$

## Expected Value

The expected value for a continuous distribution is defined as

$$
E(X)=\int x f(x)dx
$$

The expectation of a function $g(X)$ is defined as

$$
E\{g(X)\}=\int g(x)f(x)dx
$$

## Variance

The variance of continuous variable is defined as

$$
Var(X) =  E[\{X-E(X)\}^2] = \int \{X-E(X)\}^2 f(x)dx 
$$



## Uniform Distribution

A random variable is said to follow uniform distribution if the density function is constant between two parameters.

::: fragment
$$
f(x) = \left\{\begin{array}{cc}
 \frac{1}{b-a} & a \leq x \leq b\\
0 & \mathrm{elsewhere}
\end{array}\right.
$$
:::

::: fragment
$X$ can take any value between $a$ and $b$
:::

::: fragment
$X \sim U(a,b)$
:::



## Distribution (a = 4, b = 25)

```{r}
a <- 4
b <- 25
x <- seq(a, b, length.out = 1000)
p1 <- dunif(x, a, b) |> tibble(x = x, y = _) |> 
ggplot(aes(x, y)) +
geom_line() +
ylab("Density") +
ggtitle("PDF") +
theme_bw()
p2 <- punif(x, a, b) |> tibble(x = x, y = _) |> 
ggplot(aes(x,y)) +
geom_line() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```


## Distribution (a = 0, b = 1)

```{r}
a <- 0
b <- 1
x <- seq(a, b, length.out = 1000)
p1 <- dunif(x, a, b) |> tibble(x = x, y = _) |> 
ggplot(aes(x, y)) +
geom_line() +
ylab("Density") +
ggtitle("PDF") +
theme_bw()
p2 <- punif(x, a, b) |> tibble(x = x, y = _) |> 
ggplot(aes(x,y)) +
geom_line() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```

## Expectations

$$
E(X) = \frac{a+b}{2}
$$

$$
Var(X) = \frac{1}{12}(b-a)^2
$$



## Normal Distribution

A random variable is said to follow a normal distribution if the the frequency of occurrence follow a Gaussian function.

$$
f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left\{-\frac{(x-\mu)^2}{2\sigma^2}\right\}
$$

::: fragment
$X$ can take any value between $-\infty$ and $\infty$
:::

::: fragment
$X\sim N(\mu, \sigma^2)$
:::

## Distribution ($\mu$ = 34, $\sigma^2$ = 5)

```{r}
a <- 25
b <- 45
x <- seq(a, b, length.out = 1000)
p1 <- dnorm(x, 34, sqrt(5)) |> tibble(x = x, y = _) |> 
ggplot(aes(x, y)) +
geom_line() +
ylab("Density") +
ggtitle("PDF") +
theme_bw()
p2 <- pnorm(x, 34, sqrt(5)) |> tibble(x = x, y = _) |> 
ggplot(aes(x,y)) +
geom_line() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```

## Distribution ($\mu$ = -8, $\sigma^2$ = 10)

```{r}
a <- -20
b <- 4
x <- seq(a, b, length.out = 1000)
p1 <- dnorm(x, -8, sqrt(10)) |> tibble(x = x, y = _) |> 
ggplot(aes(x, y)) +
geom_line() +
ylab("Density") +
ggtitle("PDF") +
theme_bw()
p2 <- pnorm(x, -8, sqrt(10)) |> tibble(x = x, y = _) |> 
ggplot(aes(x,y)) +
geom_line() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```

## Expectations 

$$
E(X) = \mu
$$

$$
Var(X) = \sigma^2
$$

## Gamma Distribution

A gamma random variable is characterized by the gamma distribution, used to model waiting times or the time until an event occurs a certain number of times.

$$
f(x; \alpha, \beta) = \frac{x^{\alpha - 1} e^{-x/\beta}}{\beta^\alpha \Gamma(\alpha)}
$$

$$
\Gamma(\alpha) = \int_0^\infty t^{\alpha - 1} e^{-t} \, dt
$$

::: fragment
$X$ can take any value between 0 and $\infty$
:::

::: fragment
$X\sim Gamma(\alpha,\beta)$
:::

## Expectations

$$
E(X) = \alpha \beta
$$

$$
\text{Var}(X) = \alpha \beta^2
$$

## Distribution ($\alpha$ = 1.5, $\beta$ = 2.6)

```{r}
y <- rgamma(1000, 1.5, 2.6)
a <- 0
b <- 10
x <- seq(a, b, length.out = 1000)
p1 <- dgamma(x, 1.5, 2.6) |> tibble(x = x, y = _) |> 
ggplot(aes(x, y)) +
geom_line() +
ylab("Density") +
ggtitle("PDF") +
theme_bw()
p2 <- pgamma(x, 1.5, 2.6) |> tibble(x = x, y = _) |> 
ggplot(aes(x,y)) +
geom_line() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```

## Distribution ($\alpha$ = 3.5, $\beta$ = 1.6)

```{r}
y <- rgamma(1000, 3.5, 1.6)
a <- 0
b <- 10
x <- seq(a, b, length.out = 1000)
p1 <- dgamma(x, 3.5, 1.6) |> tibble(x = x, y = _) |> 
ggplot(aes(x, y)) +
geom_line() +
ylab("Density") +
ggtitle("PDF") +
theme_bw()
p2 <- pgamma(x, 3.5, 1.6) |> tibble(x = x, y = _) |> 
ggplot(aes(x,y)) +
geom_line() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```


## Distribution ($\alpha$ = 5.2, $\beta$ = 1.6)

```{r}
y <- rgamma(1000, 5.2, 1.6)
a <- 0
b <- 10
x <- seq(a, b, length.out = 1000)
p1 <- dgamma(x, 5.2, 1.6) |> tibble(x = x, y = _) |> 
ggplot(aes(x, y)) +
geom_line() +
ylab("Density") +
ggtitle("PDF") +
theme_bw()
p2 <- pgamma(x, 5.2, 1.6) |> tibble(x = x, y = _) |> 
ggplot(aes(x,y)) +
geom_line() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```

## Beta Distribution

The beta distribution is often used to model random variables that represent proportions or probabilities.

$$
f(x; \alpha, \beta) = \frac{x^{\alpha - 1} (1 - x)^{\beta - 1}}{B(\alpha, \beta)}
$$

$$
B(\alpha, \beta) = \int_0^1 t^{\alpha - 1} (1 - t)^{\beta - 1} \, dt
$$

::: fragment
$X$ can take a value between 0 and 1
:::

::: fragment
$X\sim Beta(\alpha,\beta)$
:::

## Expectations

$$
E(X) = \frac{\alpha}{\alpha + \beta}
$$

$$
\text{Var}(X) = \frac{\alpha \beta}{(\alpha + \beta)^2 (\alpha + \beta + 1)}
$$

## Distribution ($\alpha$ = 5.2, $\beta$ = 1.6)

```{r}
y <- rbeta(1000, 5.2, 1.6)
a <- 0
b <- 1
x <- seq(a, b, length.out = 1000)
p1 <- dbeta(x, 5.2, 1.6) |> tibble(x = x, y = _) |> 
ggplot(aes(x, y)) +
geom_line() +
ylab("Density") +
ggtitle("PDF") +
theme_bw()
p2 <- pbeta(x, 5.2, 1.6) |> tibble(x = x, y = _) |> 
ggplot(aes(x,y)) +
geom_line() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```

## Distribution ($\alpha$ = 1.3, $\beta$ = 1.6)

```{r}
y <- rbeta(1000, 1.3, 1.6)
a <- 0
b <- 1
x <- seq(a, b, length.out = 1000)
p1 <- dbeta(x, 1.3, 1.6) |> tibble(x = x, y = _) |> 
ggplot(aes(x, y)) +
geom_line() +
ylab("Density") +
ggtitle("PDF") +
theme_bw()
p2 <- pbeta(x, 1.3, 1.6) |> tibble(x = x, y = _) |> 
ggplot(aes(x,y)) +
geom_line() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```


## Distribution ($\alpha$ = .72, $\beta$ = .76)

```{r}
a <- .72
b <- .76
x <- seq(0, 1, length.out = 1000)
p1 <- dbeta(x, a, b) |> tibble(x = x, y = _) |> 
ggplot(aes(x, y)) +
geom_line() +
ylab("Density") +
ggtitle("PDF") +
theme_bw()
p2 <- pbeta(x, a, b) |> tibble(x = x, y = _) |> 
ggplot(aes(x,y)) +
geom_line() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
p1 + p2
```



## Distributions in R

Several common distributions can be utilized in R with the 4 common functions:

| Letter | Functionality                                                 |
|:-------|:--------------------------------------------------------------|
| `d`    | returns the height of the probability density/mass function   |
| `p`    | returns the cumulative density function value                 |
| `q`    | returns the inverse cumulative density function (percentiles) |
| `r`    | returns a randomly generated number                           |


# Random Number Generator


## Generating Random Numbers

A number is an outcome from a random experiment.

::: fragment
Random experiment is an experiment where the outcome is not predicted.
:::

::: fragment
The outcomes have a probability of being observed, whether equal or not.
:::

## Generating Random Numbers

![](https://content.presentermedia.com/files/clipart/00002000/2605/pair_of_white_dice_rolled_800_wht.jpg)

## Generating Random Numbers

![](https://www.pbs.org/newshour/app/uploads/2015/03/159615168-1024x768.jpg)

## Generating Random Numbers

![](https://cdn.mos.cms.futurecdn.net/gGpxdnJ7x3dBMrgSgKybQU-1200-80.jpg)

## Generating Random Numbers

![](https://mathbitsnotebook.com/Algebra2/Statistics/random%20table.png)

## Psuedo Random Numbers

These methods are considered time-consuming when a large number values are necessary.

::: fragment
With the advent of computers, random number can be generated with the use deterministic algorithms, where a mechanism is used to make it random, such as time.
:::

::: fragment
Computer-generated random numbers are considered psuedo random numbers because an algorithm is used to generate them given an initial single value, known as a seed.
:::

::: fragment
Supplying a seed to a random number generator will ensure that the same numbers are produced every time.
:::

## Mersenne Twister

The Mersenne Twister is a widely used pseudorandom number generator (PRNG) known for its high quality and efficiency. It was developed by Makoto Matsumoto and Takuji Nishimura in 1997. 

The default random number generator in R.


## Uniform Distribution R

::: {.panel-tabset}

## Description

The `runif` function in R will generate a value the come from a uniform distribution.

`runif` arguments:

-   `n`: number of values to generate
-   `min`: the smallest possible value to generate
-   `max`: the largest possible value to generate

## Code

```{r}
#| code-fold: show
runif(1, 0, 1)
```

:::


# Random Variable Generations

## Random Variable Generation

Several distribution, common and uncommon, can be generated using a uniform random variables.

::: fragment
More complex distributions may require the use of common distributions.
:::

## Inverse-Transform Method

```{r}
a <- -20
b <- 4
x <- seq(a, b, length.out = 1000)
pnorm(x, -8, sqrt(10)) |> tibble(x = x, y = _) |> 
ggplot(aes(x,y)) +
geom_line() +
theme_bw() +
ggtitle("CDF") +
ylab(paste0("P(X","\u2264"," x)"))
```

## Inverse-Transformation Algorithm 

1.    Generate a random value $U$ that follows a $U(0,1)$
2.    Using the CDF ($F(X)$) for random variable $X$, compute:

$$
X = F^{-1}(U)
$$


## Exponential Distribution

An exponential random variable is characterized by the exponential distribution, used to model waiting times or the time until an event occurs a certain number of times.

The exponential distribution is a gamma random variable with $\alpha = 1$.

## Exponential Distribution

$$
f(x) = \frac{1}{\lambda} \exp\left\{-\frac{x}{\lambda}\right\}
$$

$$
F(x) = 1-\exp\left\{-\frac{x}{\lambda}\right\}
$$

$$
F^{-1}(x) = -\lambda \log(1-x)
$$

## Simulating an Exponential RV

$$
X \sim Exp(2)
$$

```{r}
xe <- seq(0, 4, length.out = 1000)
u <- runif(100000)
u |> tibble(x = _) |> 
ggplot(aes(x=u, y = ..density..)) +
geom_histogram() +
geom_line(data = tibble(x = xe, y = dexp(xe, rate = 1/2)),
          mapping = aes(x,y)) +
theme_bw()
```

## Simulating an Exponential RV

```{r}
#| code-fold: show
u <- runif(100000)
x <- -2 * log(1-u)
```

## Simulating an Exponential RV

```{r}
x |> tibble(x = _) |> 
ggplot(aes(x=x, y = ..density..)) +
geom_histogram() +
geom_line(data = tibble(x = xe, y = dexp(xe, rate = 1/2)),
          mapping = aes(x,y)) +
theme_bw()
```


## Exponential RV in R

::: {.panel-tabset}
## Description

The exponential distribution can be simulated in R using the `rexp` function with the following arguments:

-   `n`: number of values to generate
-   `rate`: how fast would events occur

## Code

```{r}
#| code-fold: show
rexp(1, rate = 1)
```

:::

## Discrete RV Inverse-Transformations

1.    Generate a random value $U$ that follows a $U(0,1)$
2.    Using the CDF ($F(X)$), find the smallest integer value $k$ such that:

$$
U \leq F(k)
$$
3.    $X \leftarrow k$

## Poisson Distribution

```{r}
xe <- 0:20
u <- runif(100000)
u |> tibble(x = _) |> 
ggplot(aes(x=x, y = ..density..)) +
geom_histogram(bins = 20) +
geom_step(data = tibble(x = xe, y = dpois(xe, lambda = 6)),
          mapping = aes(x,y)) +
theme_bw()
```

## Poisson Distribution

```{r}
#| code-fold: show

finder <- function(u){
  x <- 0
  condition <- TRUE
  while (condition) {
    uu <- ppois(x, lambda = 6)
    condition <- uu <= u
    if(condition){
      x <- x + 1
    }
  }
  return(x)
}
xx <- sapply(u, finder)  
xx |> tibble(x = _) |> 
ggplot(aes(x=x, y = ..density..)) +
geom_histogram(bins = 21) +
geom_step(data = tibble(x = xe, y = dpois(xe, lambda = 6)),
          mapping = aes(x,y)) +
theme_bw()
```

## Exponential RV in R

::: {.panel-tabset}
## Description

The Poisson distribution can be simulated in R using the `rpois` function with the following arguments:

-   `n`: number of values to generate
-   `lambda`: the average expected event

## Code

```{r}
#| code-fold: show
rpois(1, lambda = 1)
```

:::

## Normal Distribution

Obtaining the inverse distribution function of a normal distribution requires the use of numeric algorithms.

::: fragment
Therefore it is computationally inefficient to use the inverse-transformation algorithm to generate normal random variables.
:::

::: fragment
The Box-Muller algorithm was developed to generate 2 standard normal ($N(0,1)$) random variables from uniform random variables.
:::

## Normal Distribution

$$
y = \int^x_{-\infty} 
\frac{1}{\sqrt{2\pi}} \exp\left\{-\frac{z^2}{2}\right\}dz
$$

## Box-Muller Algorithm

1. Generate 2 independent random variables from $U(0,1)$, $U_1$ and $U_2$
2. $X_1 = (-2 \log(U_1))^{1/2}\cos(2\pi U_2)$
3. $X_2 = (-2 \log(U_1))^{1/2}\sin(2\pi U_2)$

Both $X_1$ and $X_2$ are independent $N(0,1)$

## Normal Distribution R

::: {.panel-tabset}

## Description

The normal distribution can be simulated in R using the `rnorm` function with the following arguments:

-   `n`: number of values to generate
-   `mean`: the central tendency (peak)
-   `sd`: the variation of the data (width)

## Code

```{r}
#| code-fold: show
rnorm(1, mean = 0, sd = 1)
```

:::


## Accept-Reject Algorithm

The Accept-Reject algorithm allows you to generate noncommon random variable by simulating from a common random variable.

## Algorithm Set Up

Let $X$ be the random variable, that is difficult to generate, you want to generate with a pdf $f(x)$. 

Let $Y$ be an easily generated random variable with a pdf $g(y)$. That follows the same support as $f(x)$ 

Lastly, multiply $g(y)$ with a constant $c$ such that $f(y)\leq cf(y)$.

## Algorithm

1. Generate $Y$ with a pdf of $g(y)$
2. Generate $U$ from $U(0, cg(y))$
3. Accept-Reject
  1. Accept: $U\leq f(y)$; $Y \rightarrow X$
  2. Reject: $U>f(y)$; repeat the algorithm


## Gamma Random Variable

```{r}
xe <- seq(0, 20, length.out = 1000)
xe |> tibble(x = _) |> 
ggplot(aes(x=x, y = dgamma(x, shape = 2.3, scale = 1.2))) + 
geom_line() +
ylab("Density") +
theme_bw()
```

## Gamma RV

```{r}
xe <- seq(0, 20, length.out = 1000)
x <- rexp(100000)
x |> tibble(x = _) |> 
ggplot(aes(x=x, y = ..density..)) + 
geom_histogram(aes(color = "Exponential")) +
geom_line(data = tibble(x = xe, 
                        y = dgamma(x, shape = 2.3, scale = 1.2)), 
          aes(x,y, color = "Gamma")) +
ylab("Density") +
theme_bw() +
theme(legend.position = "bottom",
      legend.title = element_blank())
```

## Gamma RV

```{r}
xe <- seq(0, 20, length.out = 1000)
xe |> tibble(x = _) |> 
ggplot(aes(x=x, y = dgamma(x, shape = 2.3, scale = 1.2))) + 
geom_line(aes(color = "Gamma")) +
geom_line(data = tibble(x = xe, y = dexp(xe, 1/3)), aes(x,y, color = "Exponential")) +
ylab("Density") +
theme_bw() +
theme(legend.position = "bottom",
      legend.title = element_blank())
```

## Accept-Reject Gamma RV

```{r}
xe <- seq(0, 20, length.out = 1000)
xe |> tibble(x = _) |> 
ggplot(aes(x=x, y = dgamma(x, shape = 2.3, scale = 1.2))) + 
geom_line(aes(color = "Gamma")) +
geom_line(data = tibble(x = xe, y = 1.5*dexp(xe, 1/3)), aes(x,y, color = "Exponential")) +
ylab("Density") +
theme_bw() +
theme(legend.position = "bottom",
      legend.title = element_blank())
```

## Accept-Reject Gamma RV

```{r}
xe <- seq(0, 20, length.out = 1000)
xe |> tibble(x = _) |> 
ggplot(aes(x=x, y = dgamma(x, shape = 2.3, scale = 1.2))) + 
geom_line(aes(color = "Gamma")) +
geom_line(data = tibble(x = xe, y = 3*dexp(xe, 1/3)), aes(x,y, color = "Exponential")) +
ylab("Density") +
theme_bw() +
theme(legend.position = "bottom",
      legend.title = element_blank())
```

## Accept-Reject Gamma RV

```{r}
#| code-fold: show
x <- c()
n <- 0
while(n < 10000){
  e <- rexp(1, 1/2.3)
  u <- runif(1)
  f <- dgamma(e, 2.3, 1/1.2)
  g <- dexp(e, 1/2.3) * 3
  if (u < (f/g)){
    x <- c(x, e)
    n <- length(x)
  }
}

```

## Gamma RV

```{r}
x |> tibble(x = _) |> 
ggplot(aes(x=x, y = ..density..)) + 
geom_histogram(aes(color = "Exponential")) +
geom_line(data = tibble(x = xe, 
                        y = dgamma(x, shape = 2.3, scale = 1.2)), 
          aes(x,y, color = "Gamma")) +
ylab("Density") +
theme_bw() +
theme(legend.position = "bottom",
      legend.title = element_blank())

```

## Gamma Distribution R

::: {.panel-tabset}
## Description

The gamma distribution can be simulated in R using the `rgamma` function with the following arguments:

-   `n`: number of values to generate
-   `shape`: describes the shape of distribution ($\alpha$)
-   `scale`: the spread of the data ($\beta$)

## Code

```{r}
#| code-fold: show
rgamma(1, shape = 1.2, rate = .5)
```

:::

## Beta RV in R

::: {.panel-tabset}
## Description

The beta distribution can be simulated in R using the `rbeta` function with the following arguments:

-   `n`: number of values to generate
-   `shape1`: controls the shape of distribution
-   `shape2`: controls the shape of distribution

## Code

```{r}
#| code-fold: show
rbeta(1, shape1 = 1.2, shape2 = 6.5)
```

:::


## Bernoulli RV in R

::: {.panel-tabset}
## Description

The bernoulli distribution can be simulated in R using the `rbinom` function with the following arguments:

-   `n`: number of values to generate
-   `size = 1`: will give a bernoulli distribution
-   `prob`: probability of observing 1 (success)

## Code

```{r}
#| code-fold: show
rbinom(1, prob = .2, size = 1)
```

:::

## Binomial RV in R

::: {.panel-tabset}
## Description

The binomial distribution can be simulated in R using the `rbinom` function with the following arguments:

-   `n`: number of values to generate
-   `size`: how many bernoulli trials to conduct
-   `prob`: probability of observing 1 (success)

## Code

```{r}
#| code-fold: show
rbinom(1, prob = .5, size = 25)
```

:::

## Negative Binomial RV in R

::: {.panel-tabset}
## Description

The negative binomial distribution can be simulated in R using the `rnbinom` function with the following arguments:

-   `n`: number of values to generate
-   `size`: number of successful trials
-   `prob`: probability of observing 1 (success)

## Code

```{r}
#| code-fold: show
rnbinom(1, prob = .6, size = 5)
```

:::

# Transformation Methods

## $N(0,1)$

$$
X \sim N(\mu, \sigma^2)
$$


$$
Z = \frac{X-\mu}{\sigma} \sim N(0,1)
$$

## $N(\mu, \sigma^2)$

$$
Z \sim N(0,1)
$$

$$
X = Z\sigma + \mu \sim N(\mu, \sigma^2)
$$

## $\chi^2(1)$

$$
Z \sim N(0,1)
$$

$$
Z^2 \sim \chi^2(1)
$$

## $F(m,n)$

$$
U \sim \chi^2(m)
$$

$$
V \sim \chi^2(n)
$$

$$
F = \frac{U/m}{V/n} \sim F(m,n)
$$

## $t(n)$

$$
Z \sim N(0,1)
$$


$$
U \sim \chi^2(m)
$$

$$
T = \frac{Z}{\sqrt{U/m}} \sim t(n)
$$

## $Beta(\alpha, \beta)$

$$
U \sim Gamma(\alpha,\lambda)
$$

$$
V \sim Gamma(\beta,\lambda)
$$

$$
X = \frac{U}{U+V} \sim Beta(\alpha,\beta)
$$

# Central Limit Theorem

## Central Limit Theorem

If random variables $X_1, X_2, \cdots, X_n$ are independent come from the same distribution ($iid$), $E(X_i) = \mu <\infty$ (finite), $Var(X_i) = \sigma^2<\infty$ (finite), then

$$
\bar X \sim N(\mu, \sigma^2/n)
$$

## Normal Distribution

For $n$ random variables:

$$
X_i \sim N(4, 32)
$$
By CLT

$$
\bar X \sim N(4, 32 / n)
$$

## Normal Distribution

```{r}
#| code-fold: show
#| eval: false
norm <- function(x){
  rnorm(10000, 4, sqrt(32))
}
X <- sapply(1:1000, norm)
Xbar <- apply(X, 2, mean)
xx <- seq(min(Xbar)-.1, max(Xbar)+.1, length.out = 100)
Xbar |> tibble(x = _) |> 
  ggplot(aes(x=x, y = ..density..)) +
    geom_histogram() +
    geom_line(data = tibble(x = xx, y = dnorm(xx, 4, sqrt(32/10000))),
              aes(x, y))

```

## Normal Distribution

```{r}
norm <- function(x){
  rnorm(10000, 4, sqrt(32))
}
X <- sapply(1:1000, norm)
Xbar <- apply(X, 2, mean)
xx <- seq(min(Xbar)-.1, max(Xbar)+.1, length.out = 100)
Xbar |> tibble(x = _) |> 
  ggplot(aes(x=x, y = ..density..)) +
    geom_histogram() +
    geom_line(data = tibble(x = xx, y = dnorm(xx, 4, sqrt(32/10000))),
              aes(x, y)) +
    theme_bw()
```

## Poisson Distribution

```{r}
#| code-fold: true
#| eval: false
norm <- function(x){
  rpois(10000, 8.5)
}
X <- sapply(1:1000, norm)
Xbar <- apply(X, 2, mean)
xx <- seq(min(Xbar)-.1, max(Xbar)+.1, length.out = 100)
Xbar |> tibble(x = _) |> 
  ggplot(aes(x=x, y = ..density..)) +
    geom_histogram() +
    geom_line(data = tibble(x = xx, y = dnorm(xx, 8.5, sqrt(8.5/10000))),
              aes(x, y))

```

## Gamma Distribution

```{r}
#| code-fold: true
#| eval: false
norm <- function(x){
  rgamma(10000, shape = 5, scale = 2)
}
X <- sapply(1:1000, norm)
Xbar <- apply(X, 2, mean)
xx <- seq(min(Xbar)-.1, max(Xbar)+.1, length.out = 100)
Xbar |> tibble(x = _) |> 
  ggplot(aes(x=x, y = ..density..)) +
    geom_histogram() +
    geom_line(data = tibble(x = xx, y = dnorm(xx, 10, sqrt(20/10000))),
              aes(x, y))

```

## Cauchy Distribution

```{r}
#| code-fold: true
#| eval: false
norm <- function(x){
  rcauchy(10000, location = -1)
}
X <- sapply(1:1000, norm)
Xbar <- apply(X, 2, mean)
Xbar |> tibble(x = _) |> 
  ggplot(aes(x=x)) +
    geom_histogram(bins = 100)
```

