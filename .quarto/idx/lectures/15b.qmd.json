{"title":"Unsupervised \\\nMachine Learning","markdown":{"yaml":{"title":"Unsupervised \\\nMachine Learning\n","format":{"revealjs":{"scrollable":true,"include-in-header":"math_commands.html","navigation-mode":"vertical","controls-layout":"bottom-right","controls-tutorial":true,"incremental":false,"chalkboard":{"src":"chalkboard.json","storage":"chalkboard_pres","theme":"whiteboard","chalk-width":4}}},"knitr":{"opts_chunk":{"echo":true,"eval":true,"message":false,"warnings":false,"comment":"#>"}},"revealjs-plugins":["pointer","verticator"],"filters":["reveal-header","code-fullscreen","reveal-auto-agenda"],"editor":"source"},"headingText":"Unsupervised Machine Learning","containsRefs":false,"markdown":"\n\n\n## Supervised Machine Learning \n\n$$\n\\boldsymbol X = (X_1, X_2, \\cdots, X_n)\\mrTr\n$$\nwhere\n\n$$\nX_i = (x_{i1}, x_{i2}, \\cdots, x_{in})\n$$\nand\n\n$$\n\\boldsymbol Y = (Y_1, Y_2, \\cdots, Y_n)\\mrTr\n$$\n\n## Unsupervised Machine Learning\n\nGiven:\n\n$$\n\\boldsymbol X = (X_1, X_2, \\cdots, X_n)\\mrTr\n$$\nwhere\n\n$$\nX_i = (x_{i1}, x_{i2}, \\cdots, x_{in})\n$$\n\n\nGroup the data to $K$ categories.\n\n## Unsupervised Machine Learning\n\nWe can naturally group data with the following techniques:\n\n-   Principal Component Analysis\n-   K-Means Clustering\n-   Hierarchical Clustering\n-   Mixture Models\n\n## Principal Componenet Analysis\n\nPrincipal Component Analysis (PCA) is a dimensionality reduction technique used to simplify complex datasets while retaining as much of the original variability as possible. It accomplishes this by transforming the original variables into a new set of orthogonal variables called principal components. PCA is widely used in data analysis, visualization, and machine learning for tasks such as feature extraction, data compression, and noise reduction.\n\n\n## K-Means Clustering\n\nK-Means clustering is one of the most popular unsupervised machine learning algorithms used for partitioning a dataset into a predetermined number of clusters. It aims to group similar data points together and discover underlying patterns or structures within the data. K-Means is simple, efficient, and widely applicable in various domains, including data analysis, image processing, and customer segmentation.\n\n## Hierarchical Clustering\n\nHierarchical clustering is a method used to cluster data into a hierarchy of clusters. Unlike K-Means, which requires specifying the number of clusters upfront, hierarchical clustering builds a tree-like structure (dendrogram) that reflects the relationships between data points at different levels of granularity. Hierarchical clustering can be divided into two main types: agglomerative and divisive.\n\n## Mixture Models\n\nMixture models for clustering, often referred to as Gaussian Mixture Models (GMMs), are probabilistic models used to describe the distribution of data as a mixture of multiple Gaussian distributions. Unlike K-Means or hierarchical clustering, which assign data points to discrete clusters, GMMs represent each cluster as a probability distribution over the entire feature space. This allows for more flexible modeling of complex data distributions and enables soft assignment of data points to clusters based on their probabilities.\n\n# Topic Modeling with Talor Swift\n\n## Topic Modelling\n\nTopic modeling is a statistical technique used to identify latent topics or themes within a collection of text documents. It aims to uncover the underlying structure of the text data by automatically clustering documents into topics based on the distribution of words across documents. Topic modeling is widely used in natural language processing (NLP) and text mining for tasks such as document clustering, information retrieval, and content analysis.\n\n## Latent Dirichlet Allocation\n\nLatent Dirichlet Allocation (LDA) is a probabilistic model used for topic modeling in natural language processing (NLP). LDA assumes that each document in the corpus is generated by a probabilistic process involving a mixture of topics. It posits that documents exhibit multiple topics, and each word within a document is associated with one of these topics.\n\n## Structural Topic Model\n\nThe Structural Topic Model (STM) is an extension of the Latent Dirichlet Allocation (LDA) model that incorporates document metadata and covariates to capture the structural aspects of text data. Unlike LDA, which assumes that topics are generated independently of document metadata, STM allows for the incorporation of metadata or covariates associated with each document. Covariates could include document-level characteristics such as authorship, publication year, geographic location, or any other relevant metadata.\n\n## Text Mining Resource\n\n[![](https://www.tidytextmining.com/images/cover.png)](https://www.tidytextmining.com/)\n\n## R Packages\n\n```{r}\nlibrary(tidyverse)\nlibrary(taylor)\nlibrary(tidytext)\nlibrary(stm)\n```\n\n## Data Cleaning\n\n```{r}\ntidy_taylor <-\n  taylor_album_songs |>\n  unnest(lyrics) |> \n  unnest_tokens(word, lyric)\n\n\ntidy_taylor |> \n  anti_join(get_stopwords()) |> \n  count(track_name, word, sort = TRUE) |> \n  head(4)\n\n\nlyrics_sparse <-\n  tidy_taylor |> \n  count(track_name, word) |> \n  filter(n > 3) |> \n  cast_sparse(track_name, word, n)\n\n```\n\n\n## Topic Modelling\n\n```{r}\n\nset.seed(123)\ntopic_model <- stm(lyrics_sparse, K = 8, verbose = FALSE)\n```\n\n## Summary\n\n\n\n```{r}\nsummary(topic_model)\n\n```\n\n## Plot\n\n```{r}\n#| code-fold: true\nlyrics_gamma <- tidy(\n  topic_model, \n  matrix = \"gamma\",\n  document_names = rownames(lyrics_sparse)\n) \n\nlyrics_gamma |> \n  left_join(\n    taylor_album_songs |> \n      select(album_name, document = track_name) |> \n      mutate(album_name = fct_inorder(album_name))\n  ) |> \n  mutate(topic = factor(topic)) |> \n  ggplot(aes(gamma, topic, fill = topic)) +\n  geom_boxplot(alpha = 0.7, show.legend = FALSE) +\n  facet_wrap(vars(album_name)) +\n  labs(x = expression(gamma))\n\n```\n\n## Significant Effects\n\n```{r}\n#| code-fold: true\nset.seed(909)\n\neffects <-\n  estimateEffect(\n    1:8 ~ album_name,\n    topic_model,\n    taylor_album_songs |> distinct(track_name, album_name) |> arrange(track_name)\n  )\n\n\ntidy(effects) |>  \n  filter(term != \"(Intercept)\", p.value < 0.1) |> \n  select(topic, term, p.value)\n  \n```\n\n\n## Topic 3\n\n```{r}\n\ntidy(topic_model, matrix = \"lift\") |> \n  filter(topic == 3)\n\n```\n\n\n# The Missing Statistics Semester\n\n## The Missing Statistics Sememster\n\nHere is a list of resources to expand on topics not covered in your education.\n\nAdapted from <https://missing.csail.mit.edu/>\n\n## Introduction to Statistics\n\n-   [Traditional Statistics](https://bookdown.org/lgpcappiello/introstats/introduction-to-hypothesis-testing.html#p-value-approach-to-hypothesis-testing)\n-   [Modern Basic Statistics](https://openintro-ims.netlify.app/)\n-   [Statistical Modeling](https://statistical-modeling.netlify.app/)\n-   [Statistical Thinking](https://dtkaplan.github.io/Lessons-in-statistical-thinking/)\n-   [Stats for People Who Hate Stats](https://edge.sagepub.com/salkindfrey7e)\n\n## Statistical Computing\n\n-   Computational Statistics (2009, Springer; Download from CSUCI Library)\n-   Basic Elements of Computational Statistics (2017, Springer; Download from CSUCI)\n-   Optimization (2013, Springer; Download from CSUCI)\n\n## Regression\n\n-   [Beyond Linear Regression](https://bookdown.org/roback/bookdown-BeyondMLR/)\n-   [Regression Modelling Strategies](https://hbiostat.org/rmsc/) (Download from CSUCI Library)\n-   [Linear Models](https://bookdown.org/pingapang9/linear_models_bookdown/)\n-   Generalized Linear Models With Examples in R (Download from CSUCI Library)\n-   Linear and Generalized Linear Mixed Models and Their Applications (2nd Edition) (Download from CSUCI Library)\n-   Vector Generalized Linear and Additive Models; Yee (Download from CSUCI Library)\n\n## Other Statistics Resources\n\n-   [StatLect](https://www.statlect.com/)\n-   [Causal Inference](https://www.r-causal.org/)\n-   [Linear Algebra](https://shainarace.github.io/LinearAlgebra/index.html)\n\n\n## R Programming\n\n-   [Basic R](https://r4ds.hadley.nz/)\n-   [Basic R](https://jjallaire.github.io/hopr/)\n-   [Advanced R](https://adv-r.hadley.nz/)\n-   [Efficient R](https://csgillespie.github.io/efficientR/)\n-   [R Bootcamp](https://r-bootcamp.netlify.app/)\n-   [Deep R](https://deepr.gagolewski.com/index.html)\n-   [Rcpp](https://www.rcpp.org/)\n-   [Rcpp 4 Everyone](https://teuder.github.io/rcpp4everyone_en/)\n-   [Rcpp Armadillo](http://dirk.eddelbuettel.com/code/rcpp.armadillo.html)\n\n## Python Programming\n\n-   [Basic Python](https://wesmckinney.com/book/)\n-   [Anaconda](https://docs.anaconda.com/free/anaconda/install/)\n-   [Learn Python](https://www.learnpython.org/)\n-   [Python Data Science](https://jakevdp.github.io/PythonDataScienceHandbook/)\n-   [Reticulate](https://rstudio.github.io/reticulate/)\n\n## SQL\n\n-   [SQL for Data Science](https://mode.com/sql-tutorial/introduction-to-sql)\n-   [Khan Academy](https://www.khanacademy.org/computing/computer-programming/sql)\n-   [SQLBolt](https://sqlbolt.com/)\n-   [SQLZoo](https://sqlzoo.net/wiki/SQL_Tutorial)\n\n## Shell-Terminal\n\n-   [Missing Semester](https://missing.csail.mit.edu/2020/shell-tools/)\n-   [Shell](https://swcarpentry.github.io/shell-novice/)\n-   [Explain Shell](https://explainshell.com/)\n-   [Vim Adventures](https://vim-adventures.com/)\n-   [Neovim](https://neovim.io/)\n-   [tmux](https://github.com/tmux/tmux/wiki)\n-   [HPCC Manuals](https://hpcc.ucr.edu/manuals/)\n\n## Git\n\n-   [Missing Semester](https://missing.csail.mit.edu/2020/version-control/)\n-   [Happy Git](https://happygitwithr.com/)                              \n-   [Pro Git](https://git-scm.com/book/en/v2)                            \n-   [Oh S\\*\\*\\*, Git!?!](https://ohshitgit.com/)                         \n-   [Git in Simple Words](https://xosh.org/explain-git-in-simple-words/) \n\n## Markdown\n\n-   [R Mardown](https://bookdown.org/yihui/rmarkdown/)\n-   [Quarto](https://quarto.org/)\n-   [LaTeX](https://tobi.oetiker.ch/lshort/lshort.pdf)\n-   [LaTeX for Beginners](https://www.colorado.edu/aps/sites/default/files/attached-files/latex_primer.pdf)\n-   [Typst](https://typst.app/)\n\n## Dashboards\n\n-   [Shiny](https://shiny.posit.co/)\n-   [Quarto Dashboards](https://quarto.org/docs/dashboards/)\n-   [Tableau](https://www.tableau.com/learn/training)\n-   [Power BI](https://learn.microsoft.com/en-us/training/powerplatform/power-bi)\n\n\n## Other Programming\n\n-   [Cpp](https://www.learncpp.com/)\n-   [Cpp Armadillo](https://arma.sourceforge.net/)\n-   [Julia Data Science](https://juliadatascience.io/)\n-   [ArcGIS](https://learn.arcgis.com/en/gallery/)\n-   [SAS](https://www.sas.com/en_us/home.html)\n-   [Stata](https://www.stata.com/)\n-   [SPSS](https://www.ibm.com/spss)\n-   [VBA](https://learn.microsoft.com/en-us/office/vba/library-reference/concepts/getting-started-with-vba-in-office)\n-   [JMP](https://www.jmp.com/en_us/home.html)\n\n\n","srcMarkdownNoYaml":"\n\n# Unsupervised Machine Learning\n\n## Supervised Machine Learning \n\n$$\n\\boldsymbol X = (X_1, X_2, \\cdots, X_n)\\mrTr\n$$\nwhere\n\n$$\nX_i = (x_{i1}, x_{i2}, \\cdots, x_{in})\n$$\nand\n\n$$\n\\boldsymbol Y = (Y_1, Y_2, \\cdots, Y_n)\\mrTr\n$$\n\n## Unsupervised Machine Learning\n\nGiven:\n\n$$\n\\boldsymbol X = (X_1, X_2, \\cdots, X_n)\\mrTr\n$$\nwhere\n\n$$\nX_i = (x_{i1}, x_{i2}, \\cdots, x_{in})\n$$\n\n\nGroup the data to $K$ categories.\n\n## Unsupervised Machine Learning\n\nWe can naturally group data with the following techniques:\n\n-   Principal Component Analysis\n-   K-Means Clustering\n-   Hierarchical Clustering\n-   Mixture Models\n\n## Principal Componenet Analysis\n\nPrincipal Component Analysis (PCA) is a dimensionality reduction technique used to simplify complex datasets while retaining as much of the original variability as possible. It accomplishes this by transforming the original variables into a new set of orthogonal variables called principal components. PCA is widely used in data analysis, visualization, and machine learning for tasks such as feature extraction, data compression, and noise reduction.\n\n\n## K-Means Clustering\n\nK-Means clustering is one of the most popular unsupervised machine learning algorithms used for partitioning a dataset into a predetermined number of clusters. It aims to group similar data points together and discover underlying patterns or structures within the data. K-Means is simple, efficient, and widely applicable in various domains, including data analysis, image processing, and customer segmentation.\n\n## Hierarchical Clustering\n\nHierarchical clustering is a method used to cluster data into a hierarchy of clusters. Unlike K-Means, which requires specifying the number of clusters upfront, hierarchical clustering builds a tree-like structure (dendrogram) that reflects the relationships between data points at different levels of granularity. Hierarchical clustering can be divided into two main types: agglomerative and divisive.\n\n## Mixture Models\n\nMixture models for clustering, often referred to as Gaussian Mixture Models (GMMs), are probabilistic models used to describe the distribution of data as a mixture of multiple Gaussian distributions. Unlike K-Means or hierarchical clustering, which assign data points to discrete clusters, GMMs represent each cluster as a probability distribution over the entire feature space. This allows for more flexible modeling of complex data distributions and enables soft assignment of data points to clusters based on their probabilities.\n\n# Topic Modeling with Talor Swift\n\n## Topic Modelling\n\nTopic modeling is a statistical technique used to identify latent topics or themes within a collection of text documents. It aims to uncover the underlying structure of the text data by automatically clustering documents into topics based on the distribution of words across documents. Topic modeling is widely used in natural language processing (NLP) and text mining for tasks such as document clustering, information retrieval, and content analysis.\n\n## Latent Dirichlet Allocation\n\nLatent Dirichlet Allocation (LDA) is a probabilistic model used for topic modeling in natural language processing (NLP). LDA assumes that each document in the corpus is generated by a probabilistic process involving a mixture of topics. It posits that documents exhibit multiple topics, and each word within a document is associated with one of these topics.\n\n## Structural Topic Model\n\nThe Structural Topic Model (STM) is an extension of the Latent Dirichlet Allocation (LDA) model that incorporates document metadata and covariates to capture the structural aspects of text data. Unlike LDA, which assumes that topics are generated independently of document metadata, STM allows for the incorporation of metadata or covariates associated with each document. Covariates could include document-level characteristics such as authorship, publication year, geographic location, or any other relevant metadata.\n\n## Text Mining Resource\n\n[![](https://www.tidytextmining.com/images/cover.png)](https://www.tidytextmining.com/)\n\n## R Packages\n\n```{r}\nlibrary(tidyverse)\nlibrary(taylor)\nlibrary(tidytext)\nlibrary(stm)\n```\n\n## Data Cleaning\n\n```{r}\ntidy_taylor <-\n  taylor_album_songs |>\n  unnest(lyrics) |> \n  unnest_tokens(word, lyric)\n\n\ntidy_taylor |> \n  anti_join(get_stopwords()) |> \n  count(track_name, word, sort = TRUE) |> \n  head(4)\n\n\nlyrics_sparse <-\n  tidy_taylor |> \n  count(track_name, word) |> \n  filter(n > 3) |> \n  cast_sparse(track_name, word, n)\n\n```\n\n\n## Topic Modelling\n\n```{r}\n\nset.seed(123)\ntopic_model <- stm(lyrics_sparse, K = 8, verbose = FALSE)\n```\n\n## Summary\n\n\n\n```{r}\nsummary(topic_model)\n\n```\n\n## Plot\n\n```{r}\n#| code-fold: true\nlyrics_gamma <- tidy(\n  topic_model, \n  matrix = \"gamma\",\n  document_names = rownames(lyrics_sparse)\n) \n\nlyrics_gamma |> \n  left_join(\n    taylor_album_songs |> \n      select(album_name, document = track_name) |> \n      mutate(album_name = fct_inorder(album_name))\n  ) |> \n  mutate(topic = factor(topic)) |> \n  ggplot(aes(gamma, topic, fill = topic)) +\n  geom_boxplot(alpha = 0.7, show.legend = FALSE) +\n  facet_wrap(vars(album_name)) +\n  labs(x = expression(gamma))\n\n```\n\n## Significant Effects\n\n```{r}\n#| code-fold: true\nset.seed(909)\n\neffects <-\n  estimateEffect(\n    1:8 ~ album_name,\n    topic_model,\n    taylor_album_songs |> distinct(track_name, album_name) |> arrange(track_name)\n  )\n\n\ntidy(effects) |>  \n  filter(term != \"(Intercept)\", p.value < 0.1) |> \n  select(topic, term, p.value)\n  \n```\n\n\n## Topic 3\n\n```{r}\n\ntidy(topic_model, matrix = \"lift\") |> \n  filter(topic == 3)\n\n```\n\n\n# The Missing Statistics Semester\n\n## The Missing Statistics Sememster\n\nHere is a list of resources to expand on topics not covered in your education.\n\nAdapted from <https://missing.csail.mit.edu/>\n\n## Introduction to Statistics\n\n-   [Traditional Statistics](https://bookdown.org/lgpcappiello/introstats/introduction-to-hypothesis-testing.html#p-value-approach-to-hypothesis-testing)\n-   [Modern Basic Statistics](https://openintro-ims.netlify.app/)\n-   [Statistical Modeling](https://statistical-modeling.netlify.app/)\n-   [Statistical Thinking](https://dtkaplan.github.io/Lessons-in-statistical-thinking/)\n-   [Stats for People Who Hate Stats](https://edge.sagepub.com/salkindfrey7e)\n\n## Statistical Computing\n\n-   Computational Statistics (2009, Springer; Download from CSUCI Library)\n-   Basic Elements of Computational Statistics (2017, Springer; Download from CSUCI)\n-   Optimization (2013, Springer; Download from CSUCI)\n\n## Regression\n\n-   [Beyond Linear Regression](https://bookdown.org/roback/bookdown-BeyondMLR/)\n-   [Regression Modelling Strategies](https://hbiostat.org/rmsc/) (Download from CSUCI Library)\n-   [Linear Models](https://bookdown.org/pingapang9/linear_models_bookdown/)\n-   Generalized Linear Models With Examples in R (Download from CSUCI Library)\n-   Linear and Generalized Linear Mixed Models and Their Applications (2nd Edition) (Download from CSUCI Library)\n-   Vector Generalized Linear and Additive Models; Yee (Download from CSUCI Library)\n\n## Other Statistics Resources\n\n-   [StatLect](https://www.statlect.com/)\n-   [Causal Inference](https://www.r-causal.org/)\n-   [Linear Algebra](https://shainarace.github.io/LinearAlgebra/index.html)\n\n\n## R Programming\n\n-   [Basic R](https://r4ds.hadley.nz/)\n-   [Basic R](https://jjallaire.github.io/hopr/)\n-   [Advanced R](https://adv-r.hadley.nz/)\n-   [Efficient R](https://csgillespie.github.io/efficientR/)\n-   [R Bootcamp](https://r-bootcamp.netlify.app/)\n-   [Deep R](https://deepr.gagolewski.com/index.html)\n-   [Rcpp](https://www.rcpp.org/)\n-   [Rcpp 4 Everyone](https://teuder.github.io/rcpp4everyone_en/)\n-   [Rcpp Armadillo](http://dirk.eddelbuettel.com/code/rcpp.armadillo.html)\n\n## Python Programming\n\n-   [Basic Python](https://wesmckinney.com/book/)\n-   [Anaconda](https://docs.anaconda.com/free/anaconda/install/)\n-   [Learn Python](https://www.learnpython.org/)\n-   [Python Data Science](https://jakevdp.github.io/PythonDataScienceHandbook/)\n-   [Reticulate](https://rstudio.github.io/reticulate/)\n\n## SQL\n\n-   [SQL for Data Science](https://mode.com/sql-tutorial/introduction-to-sql)\n-   [Khan Academy](https://www.khanacademy.org/computing/computer-programming/sql)\n-   [SQLBolt](https://sqlbolt.com/)\n-   [SQLZoo](https://sqlzoo.net/wiki/SQL_Tutorial)\n\n## Shell-Terminal\n\n-   [Missing Semester](https://missing.csail.mit.edu/2020/shell-tools/)\n-   [Shell](https://swcarpentry.github.io/shell-novice/)\n-   [Explain Shell](https://explainshell.com/)\n-   [Vim Adventures](https://vim-adventures.com/)\n-   [Neovim](https://neovim.io/)\n-   [tmux](https://github.com/tmux/tmux/wiki)\n-   [HPCC Manuals](https://hpcc.ucr.edu/manuals/)\n\n## Git\n\n-   [Missing Semester](https://missing.csail.mit.edu/2020/version-control/)\n-   [Happy Git](https://happygitwithr.com/)                              \n-   [Pro Git](https://git-scm.com/book/en/v2)                            \n-   [Oh S\\*\\*\\*, Git!?!](https://ohshitgit.com/)                         \n-   [Git in Simple Words](https://xosh.org/explain-git-in-simple-words/) \n\n## Markdown\n\n-   [R Mardown](https://bookdown.org/yihui/rmarkdown/)\n-   [Quarto](https://quarto.org/)\n-   [LaTeX](https://tobi.oetiker.ch/lshort/lshort.pdf)\n-   [LaTeX for Beginners](https://www.colorado.edu/aps/sites/default/files/attached-files/latex_primer.pdf)\n-   [Typst](https://typst.app/)\n\n## Dashboards\n\n-   [Shiny](https://shiny.posit.co/)\n-   [Quarto Dashboards](https://quarto.org/docs/dashboards/)\n-   [Tableau](https://www.tableau.com/learn/training)\n-   [Power BI](https://learn.microsoft.com/en-us/training/powerplatform/power-bi)\n\n\n## Other Programming\n\n-   [Cpp](https://www.learncpp.com/)\n-   [Cpp Armadillo](https://arma.sourceforge.net/)\n-   [Julia Data Science](https://juliadatascience.io/)\n-   [ArcGIS](https://learn.arcgis.com/en/gallery/)\n-   [SAS](https://www.sas.com/en_us/home.html)\n-   [Stata](https://www.stata.com/)\n-   [SPSS](https://www.ibm.com/spss)\n-   [VBA](https://learn.microsoft.com/en-us/office/vba/library-reference/concepts/getting-started-with-vba-in-office)\n-   [JMP](https://www.jmp.com/en_us/home.html)\n\n\n"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","filters":["reveal-header","code-fullscreen","reveal-auto-agenda"],"include-in-header":["math_commands.html"],"incremental":false,"output-file":"15b.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.4.506","auto-stretch":true,"title":"Unsupervised \\\nMachine Learning\n","knitr":{"opts_chunk":{"echo":true,"eval":true,"message":false,"warnings":false,"comment":"#>"}},"revealjs-plugins":["pointer","verticator"],"editor":"source","scrollable":true,"navigationMode":"default","controlsLayout":"bottom-right","controlsTutorial":true,"chalkboard":{"src":"chalkboard.json","storage":"chalkboard_pres","theme":"whiteboard","chalk-width":4}}}},"projectFormats":["html"]}